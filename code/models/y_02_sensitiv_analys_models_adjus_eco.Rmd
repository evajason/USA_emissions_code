---
title: "Nonlinear models with natural spline"
author: "Yanelli Nunez"
date: "12/15/2021"
output:
 html_document:
    toc: TRUE
    toc_float: TRUE
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

*Objective:*  

Run sensitivity analysis testing for confounding by economic status

Models:
Include all economic variables, perc_white, and the race independent variable of interest

Nonlinearities:
- All economic variables include a penalized spline because we know based on the primary analysis that the associations for the economic variables are nonlinear. These models are not directly comparable to the primary analysis of course but that is a good indication that the eco variables may be nonlinear. If the variables turn out to be nonlinear, then the penalized spline will assigned degrees of freedom (df) = 1. 

- We also include all race variables with a penalized spline. If the association is linear then the penalized spline will assigned df = 1 and model the association linearly



```{r include=FALSE}

rm(list=ls())

# 1a Declare root directory
project.folder <- paste0(print(here::here()),'/')

# add folder locations
source(paste0(project.folder,'0_00_create_folder_structure.R'))

# add file locations
source(paste0(file.locations.folder,'external_file_locations.R'))

# load packages
source(paste0(packages.folder,'packages_to_load.R'))

# load functions
source(paste0(code.folder, 'models/functions.R'))

# load data
source(paste0(code.folder, 'data_loading.R'))

```

## i. View Data Summaries 
```{r}
summary(data_master)
summary(so2_energy)
```


## 1. Prep function arguments

I created a dataset with the info for the model functions' arguments (see functions.R script)

We running one model for each race/ethnic variable adjusting for all economic variables. Percent White is not included in the models_to_make dataset because all models are also adjusted for perc_white and we are extracting the results for perc_white from the model for perc_black

```{r}

### dataset containing the arguments for all models we need to run

models_to_make = c("s(perc_black)",
                   "s(perc_asian)",
                   "s(perc_nativ)",
                   "s(perc_hisp_org)") %>%
  as.data.frame() %>%
   rename(., ps_arg = .) %>%
  mutate(exposure =  c("perc_black",
                       "perc_asian",
                       "perc_nativ",
                       "perc_hisp_org")) %>%
  as.data.frame() %>%
 mutate(freq=7) %>%
  map_df(., rep, .$freq) %>%
mutate(id = rep(1:7, length.out = n())) %>%
mutate(outcome = case_when(id == 1 ~ 'so2_energy_relat_chg',  ## add outcome column
                           id == 2 ~ 'nox_energy_relat_chg', 
                           id == 3 ~ 'so2_indus_relat_chg', 
                           id == 4 ~ 'nox_trans_relat_chg', 
                           id == 5 ~ 'nh3_agric_relat_chg', 
                           id == 6 ~ 'oc_resid_relat_chg', 
                           id == 7 ~ 'nox_commer_relat_chg')) %>%
  dplyr::select(-freq, -id) %>%
   mutate(data_spf = if_else(outcome == "so2_energy_relat_chg", "so2_energy",
                      if_else(outcome == "so2_indus_relat_chg", "so2_inds",
                        if_else(outcome == "nox_energy_relat_chg", "nox_energy", "data_master")))) %>%
  arrange(outcome)
  
```


## 2. Progress bar 

Parallelize: runs the iterations in parallel across multiple cores to increase speed
You computer has multiple processing cores but it only uses one to ran your R code. Parallelizing the procesing means that you are telling your computer to run different portions of your code simultaneously in multiple cores. This results in an overall faster processing

```{r}

#### set up a progress bar
pb <- txtProgressBar(min = 0, max = nrow(models_to_make), width = 25, style = 3)
progress <- function(p) setTxtProgressBar(pb, p)
opts <- list(progress=progress)

### code to paralized the processing among multiple cores
cores <- ceiling(parallel::detectCores() / 2) # use half of the available cores 
cluster <- snow::makeCluster(cores) 
doSNOW::registerDoSNOW(cluster)

```


## 3. Run models

- We using the foreach() function to loop our function over each row of the datasets defined in point 1.
Note this code chunk takes awhile to run. I recommend running it over night. 

```{r}

### run the foreach() loop (I am parallelizing this process to make it faster)
         
models_adjs_eco <- foreach(i = iterators::icount(nrow(models_to_make)), # iterate across rows
                             .options.snow=opts, # the progress bar being sent to each core
                             .packages=c("Epi", "magrittr", "dplyr", "janitor", "ggplot2"), # the packages being sent to each core
                             .export = ls(globalenv()),
                             .inorder = FALSE, # speeds up parallel programming
                             .combine = rbind) %dopar% { # if you doing parallel programming use %dopar% otherwise use %do%
  
  # make model i
  m <- run_model_eco_adjus(data = models_to_make$data_spf[[i]],
                        outcome = models_to_make$outcome[[i]], 
                       exposure = models_to_make$ps_arg[[i]]) # the spline term
  
  df <- models_to_make[i,] %>% mutate(models = list(m))
  
 
  # save our work
  df
  
}

# stop the parellel processing
snow::stopCluster(cluster)
close(pb)

```


## 5. Save file

```{r}

#saveRDS(models_adjs_eco, paste0(yanelli_external, "results_updated/sensit_analy_models_adjs_eco.rds"))

```


